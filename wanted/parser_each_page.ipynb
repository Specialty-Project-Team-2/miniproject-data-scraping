{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from util.file_handler import load_file, saveAsJson, make_file_path, iterator_dir_children, create_directory_if_not_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 경로 내부의 모든 파일을 Generator로 가져오기.\n",
    "SOURCE_DIR = \"wanted\"\n",
    "\n",
    "file_children_for_json = iterator_dir_children(SOURCE_DIR)\n",
    "file_children_for_file_name = iterator_dir_children(SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 공간 확보\n",
    "ROOT_DIR = \"wanted_json\"\n",
    "\n",
    "create_directory_if_not_exists(make_file_path(ROOT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_soup(file_path):\n",
    "    # 파일 가져오기\n",
    "    html_content = load_file(file_path)\n",
    "    \n",
    "    # BeautifulSoup를 사용하여 HTML 파싱\n",
    "    return BeautifulSoup(html_content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list(section_image):\n",
    "    if not section_image: return None\n",
    "    \n",
    "    image_tags = section_image.find_all(name=\"img\")\n",
    "    return [i[\"src\"] for i in image_tags]\n",
    "\n",
    "def get_job_name(section_job_header):\n",
    "    if not section_job_header: return None\n",
    "    \n",
    "    return section_job_header.h2.string\n",
    "\n",
    "def get_company_name(section_job_header):\n",
    "    if not section_job_header: return None\n",
    "    \n",
    "    return section_job_header.find(name=\"a\", attrs={\"data-attribute-id\": \"company__click\"}).string\n",
    "\n",
    "def get_tags(section_job_header):\n",
    "    if not section_job_header: return None\n",
    "    \n",
    "    ul_tags = section_job_header.find(name=\"div\", attrs={\"class\": \"Tags_tagsClass__mvehZ\"})\n",
    "    li_list_tags = ul_tags.find_all(name=\"li\")\n",
    "    return [i.a.string for i in li_list_tags]\n",
    "\n",
    "def get_job_description(section_job_description):\n",
    "    if not section_job_description: return None\n",
    "    \n",
    "    return str(section_job_description)\n",
    "\n",
    "def get_location(section_location):\n",
    "    if not section_location: return None\n",
    "    \n",
    "    return section_location.find(name=\"span\", attrs={\"class\": \"body\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_to_json(soup):\n",
    "    root_element = soup.find(name=\"div\", attrs={\"class\": \"JobContent_className___ca57\"})\n",
    "    \n",
    "    if not root_element: return {}\n",
    "\n",
    "    section_image = root_element.find(name=\"section\", attrs={\"class\": \"JobImage_JobImage__OFUyr\"})\n",
    "    section_job_header = root_element.find(name=\"section\", attrs={\"class\": \"JobHeader_className__HttDA\"})\n",
    "    section_job_description = root_element.find(name=\"section\", attrs={\"class\": \"JobDescription_JobDescription__VWfcb\"})\n",
    "    section_location = root_element.find(name=\"section\", attrs={\"class\": \"JobWorkPlace_className__ra6rp\"})\n",
    "    \n",
    "    root_element = None\n",
    "    \n",
    "    return {\n",
    "        \"images\": get_image_list(section_image),\n",
    "        \"job_name\": get_job_name(section_job_header),\n",
    "        \"company_name\": get_company_name(section_job_header),\n",
    "        \"tags\": get_tags(section_job_header),\n",
    "        \"job_description\": get_job_description(section_job_description),\n",
    "        \"location\": get_location(section_location),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_from_url(url : str):\n",
    "    return url.rpartition(\"\\\\\")[-1].partition(\".\")[0]\n",
    "\n",
    "def get_file_name_from_id(id):\n",
    "    return f\"wanted_parsed_json_{id}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 생성\n",
    "iter_url_for_json = file_children_for_json\n",
    "iter_soup = map(html_to_soup, iter_url_for_json)\n",
    "iter_json = map(soup_to_json, iter_soup)\n",
    "\n",
    "iter_url_for_file_name = file_children_for_file_name\n",
    "iter_id = map(extract_id_from_url, iter_url_for_json)\n",
    "iter_file_name = map(get_file_name_from_id, iter_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "for json, file_name in zip(iter_json, iter_file_name):\n",
    "    saveAsJson(make_file_path(f\"{ROOT_DIR}/{file_name}\"), json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
